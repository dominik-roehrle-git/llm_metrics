{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import LLama2\n",
    "import os\n",
    "import pandas as pd\n",
    "from generateEvidence import GenerateEvidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat model: meta-llama/Llama-2-7b-chat-hf\n",
    "# llama2 model: meta-llama/Llama-2-7b-hf\n",
    "model = LLama2(model_id=\"meta-llama/Llama-2-7b-chat-hf\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test\n",
    "\n",
    "to test if the generation in the virtual environment works you can use the following cell. It only produces one generation per subset. \n",
    "After the run go to evaluation_files/test/generation and you see the generated text from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate = GenerateEvidence(model=model,file_example_path='./hover_dataset/hover_claim_evidence_example.json', file_test_path='./hover_dataset/hover_claim_evidence_test.json', \n",
    "                                number_examples=6,\n",
    "                                max_tokens=512)\n",
    "\n",
    "# or directory_path = \"./evaluation_files/basic_llama2/generation/\"\n",
    "directory_path = \"./evaluation_files/test/generation/\"\n",
    "\n",
    "\n",
    "for hops in range(2,5):\n",
    "    for supports in [\"SUPPORTS\", \"REFUTES\"]:\n",
    "        prompt = generate.get_prompt(supports_option=\"SUPPORTS+REFUTES\", hops_option='mixed')\n",
    "        \n",
    "  \n",
    "        df = generate.generate_evidence(prompt, supports=supports, hops=hops, number_generations=1)\n",
    "        filename = os.path.join(directory_path, f\"{supports.lower()}_hops{hops}.csv\")\n",
    "        df.to_csv(filename, index=False)\n",
    "        generate.reset_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate = GenerateEvidence(model=model,file_example_path='./hover_dataset/hover_claim_evidence_example.json', file_test_path='./hover_dataset/hover_claim_evidence_test.json', \n",
    "                                number_examples=6,\n",
    "                                max_tokens=512)\n",
    "\n",
    "# or directory_path = \"./evaluation_files/basic_llama2/generation/\"\n",
    "directory_path = \"./evaluation_files/basic_llama2_chat/generation/\"\n",
    "\n",
    "\n",
    "for hops in range(2,5):\n",
    "    for supports in [\"SUPPORTS\", \"REFUTES\"]:\n",
    "        prompt = generate.get_prompt(supports_option=\"SUPPORTS+REFUTES\", hops_option='mixed')\n",
    "        \n",
    "  \n",
    "        df = generate.generate_evidence(prompt, supports=supports, hops=hops)\n",
    "        filename = os.path.join(directory_path, f\"{supports.lower()}_hops{hops}.csv\")\n",
    "        df.to_csv(filename, index=False)\n",
    "        generate.reset_data()\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate = GenerateEvidence(model=model,file_example_path='./hover_dataset/hover_claim_evidence_example.json', file_test_path='./hover_dataset/hover_claim_evidence_test.json', \n",
    "                                number_examples=6,\n",
    "                                max_tokens=512)\n",
    "\n",
    "\n",
    "directory_path = \"./evaluation_files/variation1_llama2_chat/generation/\"\n",
    "\n",
    "\n",
    "for hops in range(2,5):\n",
    "    for supports in [\"SUPPORTS\", \"REFUTES\"]:\n",
    "        prompt = generate.get_prompt(supports_option=\"SUPPORTS\", hops_option='mixed')\n",
    "        \n",
    "  \n",
    "        df = generate.generate_evidence(prompt, supports=supports, hops=hops)\n",
    "        filename = os.path.join(directory_path, f\"{supports.lower()}_hops{hops}.csv\")\n",
    "        df.to_csv(filename, index=False)\n",
    "        generate.reset_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variation 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate = GenerateEvidence(model=model,file_example_path='./hover_dataset/hover_claim_evidence_example.json', file_test_path='./hover_dataset/hover_claim_evidence_test.json', \n",
    "                                number_examples=6,\n",
    "                                max_tokens=512)\n",
    "\n",
    "\n",
    "directory_path = \"./evaluation_files/variation2_llama2_chat/generation/\"\n",
    "\n",
    "\n",
    "for hops in range(2,5):\n",
    "    for supports in [\"SUPPORTS\", \"REFUTES\"]:\n",
    "        prompt = generate.get_prompt(supports_option=\"REFUTES\", hops_option='mixed')\n",
    "        \n",
    "  \n",
    "        df = generate.generate_evidence(prompt, supports=supports, hops=hops)\n",
    "        filename = os.path.join(directory_path, f\"{supports.lower()}_hops{hops}.csv\")\n",
    "        df.to_csv(filename, index=False)\n",
    "        generate.reset_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variation 3: Prompt Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate = GenerateEvidence(model=model,file_example_path='./hover_dataset/hover_claim_evidence_example.json', file_test_path='./hover_dataset/hover_claim_evidence_test.json', \n",
    "                                number_examples=2,\n",
    "                                max_tokens=512)\n",
    "\n",
    "# or directory_path = \"./evaluation/basic_llama2/generation/\"\n",
    "directory_path = \"./evaluation_files/variation3_llama2_chat/\"\n",
    "\n",
    "for i in range(2, 9, 2):\n",
    "    if i == 6 or i == 8:\n",
    "        pass\n",
    "    else:\n",
    "        for hops in range(2,5):\n",
    "            for supports in [\"SUPPORTS\", \"REFUTES\"]:\n",
    "                generate.set_generate_text(max_tokens=512, number_examples=i)\n",
    "                prompt = generate.get_prompt(supports_option=\"SUPPORTS+REFUTES\", hops_option='mixed')\n",
    "                df = generate.generate_evidence(prompt, supports=supports, hops=hops)\n",
    "                prompt_size_directory = os.path.join(directory_path, f\"prompt_size{i}/generation/\")\n",
    "                filename = os.path.join(prompt_size_directory, f\"{supports.lower()}_hops{hops}.csv\")\n",
    "                df.to_csv(filename, index=False)\n",
    "                generate.reset_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
